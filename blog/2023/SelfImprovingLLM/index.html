<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>LLM이 스스로 발전할 수 있을까? | Seungyoun Shin(신승윤)</title> <meta name="author" content="Seungyoun Shin"> <meta name="description" content="dd"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@400;700&amp;display=swap" rel="stylesheet"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/colorful.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%92%A1&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://seungyounshin.github.io/blog/2023/SelfImprovingLLM/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "LLM이 스스로 발전할 수 있을까?",
      "description": "dd",
      "published": "December 30, 2023",
      "authors": [
        {
          "author": "신승윤",
          "authorURL": "",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-bolder" href="https://SeungyounShin.github.io/">Seungyoun Shin(신승윤)</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>LLM이 스스로 발전할 수 있을까?</h1> <p>dd</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#draft">Draft</a></div> </nav> </d-contents> <h2 id="draft">Draft</h2> <h3 id="self-correction">Self Correction</h3> <p><a href="https://ar5iv.labs.arxiv.org/html/2303.11366" rel="external nofollow noopener" target="_blank"><strong>Reflexion</strong></a></p> <p>너무나도 유명한 논문이다. 이전에 틀렸으면 다시 반추(Reflection) 하면 원래 결과보다 계속 잘해지게 된다는 내용인데 현실적으로는 적용하기 어렵다. 왜냐하면, 우선 해당 논문에서는 Oracle Feedback 을 받는다. 예를 들어 HumanEval 과 같은 코딩문제에서는 Programming Judge 로 부터 맞았는지 틀렸는지를 알수가 있다. 밑에 <strong>Large Language Models Cannot Self-Correct Reasoning Yet</strong> 에서는 이런 Error Singal 을 흘려주는 것은 진정한 Self Correction이 아니라고 말하고 있고 나도 이 주장이 상당히 신빙성이 있다고 느껴진다. 하지만, 처음 Reflection 이라는 개념을 제안했다는 측면에서 꽤 의미 있는 논문인것 같다. 여담이지만 Neuirps 에 갔을 때 포스터에 저자가 와서 물어봤었다 ㅎㅎ 저자도 뭔가 다음 스텝을 생각하는 느낌이었다. 왜냐면 결국 성능이 Saturated 된다. 특정 성능 이상은 모델의 개별성능을 넘을 수 없다는것이다. 인간도 계속 생각하다 보면 어떤 문제는 풀 수 있지만 그래도 어떻게든 못푸는 문제가 존재하는것과 동일하다고 생각이된다.</p> <p><a href="https://arxiv.org/abs/2310.01798" rel="external nofollow noopener" target="_blank"><strong>Large Language Models Cannot Self-Correct Reasoning Yet</strong></a></p> <p>몰랐는데 이 논문이 ICLR2024에 Submit 되었다 결과는 어떻게 될지 모르겠지만 이 당시에는 Self Correction 하는 방법론들이 우후죽순 나오고있던 때라 Self Correction 이 단순히 Accuracy 가 올라가는것만 보면안되고 맞았다가 틀려진 것과 틀렸는데 맞아진것을 같이 보면 결국은 LLM이 아직은 Self Correcting 을 못한다는 내용이다. 근데 실제 해보면 논문의 말처럼 맞았는데 틀려지는게 꽤 된다.</p> <h3 id="synthetic-data-self-training">Synthetic Data Self-Training</h3> <p><a href="https://cdn.openai.com/papers/weak-to-strong-generalization.pdf" rel="external nofollow noopener" target="_blank"><strong>weak to strong(OpenAI)</strong></a></p> <p>많은 사람들이 대체 왜 그냥 Strong 모델을 훈련시키기 않냐고 비난을 받는 논문인데. 그치만 가만 생각해보면 이 세팅은 다른 어떤 논문보다 Synthetic data 를 진지하게 다루고 있다고 생각한다. 절대 이 논문의 세팅은 strong 모델을 제한하려는 방향이 아니다. weak LLM의 아웃풋 (즉, 사람이 될수도 있다) 을 가지고 이것을 $P_\text{data}$ 로 이용한다면, 결국 SFT를 하든 뭐를 하든 Global Maximum 인 사람 그 자체를 넘어서지 못한다. 근데 해당 논문에서는 이를 넘어설수 있음을 보였다. 하지만 아직 오점이 많다. 논문에서 이야기하는 strong LLM 이 사람을 넘어서는 것은 아니다 ($\texttt{MMLU} \le 90\%$) 즉, 사람을 넘어서는 아주 새로운 synthetic data가 아니라 $P_\text{data}$ 를 가지고 훈련된 underfitting 된 모델 끼리의 weak-to-strong 을 논의하고 있다.</p> <p><a href=""><strong>Reinforced Self-Training (ReST) for Language Modeling</strong></a></p> <p>Grow Step 과 Improving Step 으로 나뉘어 스스로 성장하는 LLM을만드는것인데 translation 에서만 실험을 한것이 아쉽다.</p> <p><a href="https://ar5iv.labs.arxiv.org/html/2308.08998" rel="external nofollow noopener" target="_blank"><strong>Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models</strong></a></p> <p>사람을 넘기위해서는 사람의 데이터를 모사하면 안됨. Synthetic Data 를 만들고 Scalar Feedback 을 만들어서 이걸 가지고 단순히 MMLU나 TriviaQA와 같은 언어쪽 도메인이 아니라 정말 Reasoning 이 필요한 MATH, Code(APPS, HumanEval) 에서의 정확도 향상을 보이는 논문임.</p> <p><a href="https://ar5iv.labs.arxiv.org/html/2310.10047" rel="external nofollow noopener" target="_blank"><strong>Improving Large Language Model Fine-tuning for Solving Math Problems</strong></a></p> <p>Pass@1 하고 Pass@K 즉 LLM 에서 여러번 Sampling 하면 성공하는 비율과 단번에 풀어버리는 비율이 수학이나 코딩쪽에서 꽤 많이 차이가 난다. 이걸 개선하는 논문인듯</p> <p><a href="https://arxiv.org/abs/2401.01335" rel="external nofollow noopener" target="_blank"><strong>Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models</strong></a></p> <p>RL로 LLM을 튜닝하는 방법은 Preference 를 필요로한다. SFT 세팅에서 같은 모델($\theta$)를 Generator, Discriminator로 생성해보고 $P_\text{data}$ 인 보통은 인간이나 GPT4가 생성한 데이터와 가까워지고 본인이 이전에 생성한것 과는 멀어지는 방향으로 학습하게된다. 수학적 수식을 통해 훈련 Loss 를 간단하게 도출한 점이 매우 훌룡한 것 같다.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Seungyoun Shin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>